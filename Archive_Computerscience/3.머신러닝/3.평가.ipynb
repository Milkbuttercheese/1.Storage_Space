{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## CH3 평가\n### 다양한 평가기준들\n- 평가 관련 용어\n\t- 정분류\n\t\t- True-Positive: 실제 결과값이 1 인것을 양성(1)으로 예측한다 \n\t\t- True- Negatvie: 실제 결과값이 0 인것을 음성(0)으로 예측한다\n\t- 오분류\n\t\t- False- Positive: 양성(1)이라 예측했지만 실제 결과값이 0이다\n\t\t-  False- Negative: 음성(0)이라 예측했지만 실제 결과값이 1이다\n- 다양한 평가기준들\n\t- 정확도 $accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$ : 모든 예측중 제대로 예측한 것의 비율\n\t- 정밀도 $precision=\\frac{TP}{TP+FP}$ : 참이라고 예측한 것중 실제로 참인 것의 비율\n\t- 재현율/민감도 $recall/sensitivity=\\frac{TP}{TP+FN}$ :실제로 참인것들 중 참이라고 예측한 비율\n\t\t- FN가 발생해선 안되는 업무에서 중요지표가 된다. \n\t\t- 예) 암검진\n\t- 특이도 $specificity=\\frac{TN}{TN+FP}$ : 실제로 거짓인 것중 거짓이라 예측한 것의 비율\n\t- FP가 발생해선 안되는 업무에서 중요지표가 된다\n\t- 예) 업무메일을 스팸으로 차단하는 경우\n\n### 다양한 평가기준을 사용하는 이유 - 자동검진 기계와 타이타닉\n- 높은 정확도면 좋은 알고리즘인가?: 1000명중 1명이 걸리는 희귀병이 있다하자. 이 병을 자동으로 진단해주는 기계가 있는데 아무도 모르게 어느날 고장이 나서 무조건 음성판정을 내린다고 하자.  이 기계의 정확도는 999/1000이지만 아무짝에도 쓸데가 없다. 왜냐면 *예측한 것이 들어맞는 비율이 높은것 보다도, 실제 양성인 환자가 양성으로 판별되는 비율이 중요하기 때문이다.*\n- 타이타닉에서 여성이면 생존, 남성이면 사망이라고만 분류하는 단순한 이 알고리즘도 0.788의 높은 정확도를 가지고 있다\n```python\n#BaseEstimator: Base class for all estimators in scikit-learn.  \nclass MyDummyClassifier(BaseEstimator):  \n    #fit 메소드는 아무것도 학습시키지 않는다  \n    def fit(self,x,y=None):  \n        pass  \n    # predict() 메소드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측한다  \n    def predict(self,X):  \n        pred= np.zeros((X.shape[0],1))  \n        for i in range(X.shape[0]):  \n            if X['Sex'].iloc[i] == 1:  \n                pred[i] = 0  \n            else:  \n                pred[i] = 1  \n        return pred  \n  \n#챕터 2에서 만들어둔 모듈을 가져옴  \nfrom titanic_preprocessing import preprocessing_feature  \n#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터를 분할한다  \ntitanic_df =pd.read_csv('./train.csv')  \ny_titanic_df= titanic_df['Survived']  \nX_titanic_df = titanic_df.drop('Survived',axis=1)  \nX_titanic_df= preprocessing_feature(X_titanic_df)  \n  \nX_train, X_test, y_train, y_test= train_test_split(X_titanic_df,y_titanic_df,test_size=0.2,random_state=0)  \n  \n#위의 Dummy_Classifier 모델을 이용하여 학습/예측 평가해보자  \nmyclf= MyDummyClassifier()  \nmyclf.fit(X_train,y_train)  \n  \nmypredictions= myclf.predict(X_test)  \nprint(f'Dummy Classifier의 정확도는 {accuracy_score(y_test,mypredictions):.3f}')\n\n____________________________________________________________\nresult)\nDummy Classifier의 정확도는 0.788\n```\n\n## 2. 오차행렬 / 혼돈행렬 confounding matrix\n- 입력\n\t- `sklearn.metrics.confusion_matrix(y_true y_pred)`\n- 출력\n\t- 다음의 값을 만족하는 $C_{ij}$ 로 구성된 행렬이 만들어진다\n\t\t- $C_{ij}$ 는 $j$ 번 클래스로 예측되고, $i$번이 실제의 값인 데이터의 수다.\n\t\t- 즉 $j$ 번째 열은 $j$ 번째 클래스를 예측하는 것이고, $i$ 번째 행은 $i$ 번째 실제 클래스인것이다\n\n## 3. 정밀도와 재현율의 Tradeoff\n- 정밀도와 재현율의 *tradeoff*\n\t- 정밀도 $precision=\\frac{TP}{TP+FP}$ 와 재현율 $recall=\\frac{TP}{TP+FN}$ 은 상호보완적인 평가지표로서 한쪽을 높이면 다른 한쪽의 수치가 떨어지기 쉽다\n-  `predict_proba`\n\t- 다음의 값을 만족시키는 $P_{ij}$로 구성된 행렬이 만들어진다\n\t- $P_{ij}$ 는 $j$번 클래스로 예측되고, $i$번째 값이 되는 함수이다\n\t- `pred` 메서드는 `predict_proba` 에 기반한 메서드로서, 대부분의 경우 `predict_proba` 의 `i` 번째 행에서 가장 큰 확률값을 갖는 $P_{i\\tilde{j}}$ 를 찾아, $\\tilde{j}$를 클래스 값으로 예측한다\n\t- 그러나 더 일반적으로는 각 클래스의 확률이 특정 기준을 넘어서면 해당 클래스로 예측하는데, 이때 기준값을 임계값threshold라고 한다.\n\t\n-  임계값을 설정하여 예측하기\n```python\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix  \n  \ndef get_clf_eval(y_test,pred):  \n    confusion= confusion_matrix(y_test,pred)  \n    accuracy = accuracy_score(y_test,pred)  \n    precision= precision_score(y_test,pred)  \n    recall= recall_score(y_test,pred)  \n    print('오차 행렬')  \n    print(confusion)  \n    print(f'정확도 {accuracy:.3f} 정밀도 {precision:.3f} 재현율 {recall:.3f} ')  \n  \n#Binzarizer의 threshold 설정값. 분류 결정 임계값임  \ncustom_threshold= 0.5  \n#predit_proba()의 반환값의 두번째 컬럼, 즉 positive 클래스 컬럼중 하나만 추출하여 Binarizer를 적용시킨다  \npred_proba_1 = pred_proba[:,1].reshape(-1,1)  \n  \nbinarizer= Binarizer(threshold=custom_threshold).fit(pred_proba_1)  \ncustom_predict= binarizer.transform(pred_proba_1)  \nget_clf_eval(y_test,custom_predict)\n\n-----------------------------------------------------------------------\nresult)\n오차 행렬\n[[108  10]\n [ 16  45]]\n정확도 0.855 정밀도 0.818 재현율 0.738\n```\n- 임계값을 0.5에서 0.4로 수정한 경우\n```python\n#Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임계값을 0.5에서 0.4로 낮춘다  \ncustom_threshold= 0.4  \npred_proba_1= pred_proba[:,1].reshape(-1,1)  \nbinarizer= Binarizer(threshold=custom_threshold).fit(pred_proba_1)  \ncustom_predict= binarizer.transform(pred_proba_1)  \n  \nget_clf_eval(y_test,custom_predict)\n________________________________________________________________________\nresult)\n오차 행렬\n[[98 20]\n [11 50]]\n정확도 0.827 정밀도 0.714 재현율 0.820\n```\n- 위의 두 예제에서 보듯 임계값을 낮추니 재현율이 올라가고 정밀도가 떨어지게 되었다. 왜 그럴까?\n- 증명\n\t- 임계값을 낮출수록 Positive 예측수가 늘어난다. 이를 $PP$라고 표기하자\n\t- $PP=TP+FP$ 이다\n\t- 재현율 $reacall=\\frac{TP}{TP+FN}$ 이고, 정밀도 $precision=\\frac{TP}{TP+FP}$ 라는 식을 고려하자\n\t- 재현율을 보자 이경우  $PP$ 가 증가한다 해서 $FN$ 가 증가하지 않으므로 $TP$ 가 유일하게 변하는 변수이다 \n\t\t- $\\frac{\\partial{Recall}}{\\partial{TP}}=\\frac{1}{TP+FN}+TP\\cdot\\frac{\\partial{}}{\\partial{TP}}\\cdot\\frac{1}{(TP+FN)}=\\frac{1}{TP+FN}-\\frac{TP}{(TP+FN)^2}=\\frac{FN}{(TP+FN)^2}>0$\n\t- 정밀도를 보자. $PP$ 가 증가하는 경우 , \n\t\t- $\\frac{\\partial{Precision}}{\\partial{PP}}=\\frac{-TP}{PP^2}++\\frac{1}{PP}\\cdot\\frac{\\partial{TP}}{\\partial{PP}}=\\frac{1}{PP}(\\frac{\\partial{TP}}{\\partial{PP}}-\\frac{TP}{PP})$\n\t\t- $FP$ 만 증가하는 경우 \n\t\t\t- 재현율 $recall$ 가 증가하진 않는다\n\t\t\t- 정밀도 $\\frac{\\partial{Precision}}{\\partial{FP}}=-\\frac{TP}{(TP+FP)^2}$ 로 정밀도가 떨어진다\n\t- 종합적으로 보면 \n\t\t- 임계값을 낮추면 재현율은 항상 높아진다\n\t\t- 임계값을 낮추었을 때 $TP$의 비율이 높은경우 정밀도가 높아지고, $FP$의 비율이 높은경우 정밀도가 낮아진다 ( 그러나 그래프에서 보면 대체로 항상 낮아지는 듯)\n\t\t- ![](Pasted%20image%2020220720113044.png)\n\t- 정밀도가 100%가 되기 위해선 확실히 기준이 되는 경우에만 positive로 예측하고 나머지는 모두 negative로 예측한다\n\t- 재현율이 100%가 되기 위해선 모든 분류를 positive로 예측한다\n\n### 4.F-1 스코어\n- 정밀도와 재현율을 결합한 지표이다\n- 정밀도와 재현율이 어느 한쪽으로 치우치지 않을 때 상대적으로 높은 값을 갖는다\n- $F_1=\\frac{2}{\\frac{1}{Recall}+\\frac{1}{Precision}}=2\\cdot \\frac{Precision \\cdot Recall}{Precision+Recall}$\n- $dF_1=\\frac{\\partial F_1}{\\partial(Recall)}\\cdot d(Recall)+\\frac{\\partial F_1}{\\partial{Precision}}\\cdot d(Precision)$\n- $=2(-\\frac{Precision \\cdot Recall}{(Precision+Recall)^2}+\\frac{Precision}{Precision+Recall})\\cdot d(Recall)+2(-\\frac{Precision \\cdot Recall}{(Precision+Recall)^2}+\\frac{Recall}{Precision+Recall})\\cdot d(Precision)$\n- $=2(\\frac{Precision^2}{(Precision+Recall)^2}d(Recall)+\\frac{Recall^2}{(Precision+Recall)^2}d(Precision))$ ( 증명 미완..)\n\n## 5.ROC와 관련 측정 개념들\n- $FPR- False \\,Postive\\, Rate=\\frac{FP}{TN+FP}$: 실제 음성중에서 잘못 양성으로 예측하는 비율 \n- $TNR-True\\,Negate\\,Rate$-특이성 $\\,Specificity= \\frac{TN}{TN+FP}$ : 실제 음성중 음성이라 예측하는 비율\n- $ROC=\\frac{TPR}{FPR}=\\frac{Recall}{FPR}$\n- 그래프 시각화하기\n```python\ndef roc_curve_plot(y_test,pred_proba_c1):\nfprs, tprs, thresholds= roc_curve(y_test,pred_proba_c1)\n#ROC 곡선을 그래프 곡선으로 그린다\nplt.plot(fprs,tprs,label='ROC')\n#가운데 대각선 직선을 그린다\nplt.plot([0,1],[0,1],'k--',label='random')\n# FPR X 축의 scale을 0.1 단위로 변경. X축 Y축명 설정등\nstart, end = plt.xlim()\nplt.xticks(np.round(np.arange(start,end,0.1),2))\nplt.xlim(0,1); plt.ylim(0,1)\nplt.xlabel('FPR(1-Sensitivity'); plt.ylabel('TPR(Recall)')\nplt.legend()\n  \n\nroc_curve_plot(y_test,pred_proba[:,1])\n```\n\n",
   "metadata": {
    "cell_id": "a27ee7c24e194f489ff6768ff3511a42",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 4784.609375
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "cell_id": "03e96b0bdf6f46238092d47618b2fa78",
    "tags": [],
    "owner_user_id": "6620e961-4734-4451-b6f0-024902f1a0c6",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 46
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5a548db0-9bec-4ed6-b090-9c062f32efdb' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "7f8c9fc8-6d4d-4f18-902b-3f1cbfc10578",
  "deepnote_execution_queue": []
 }
}
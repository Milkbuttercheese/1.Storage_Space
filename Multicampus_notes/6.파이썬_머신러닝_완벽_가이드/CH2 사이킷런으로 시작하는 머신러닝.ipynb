{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "fa300a44-e15b-42c2-98e8-13455a10c76d",
    "deepnote_cell_type": "code"
   },
   "source": "#데이터 핸들링 라이브러리\nimport numpy as np\nimport pandas as pd\n\n#통계 라이브러리\nfrom scipy import stats\n\n#머신러닝 라이브러리\nimport sklearn\n#정확도 측정 함수\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n#시각화 라이브러리\nimport matplotlib.pyplot as plt\nimport seaborn as sns",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "|## 첫번째 머신러닝 모델- 붓꽃 품종 예측",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "cell_id": "00001-d79f6b65-b786-409d-8ba2-9affdb88d91b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00002-7785e01e-c626-40e5-a7f5-20db81722264",
    "deepnote_cell_type": "code"
   },
   "source": "# 데이터 import 하기\nfrom sklearn.datasets import load_iris\n#의사결정 트리 classifier import하기\nfrom sklearn.tree import DecisionTreeClassifier\n#훈련,테스트 세트 분리 함수 import 하기\nfrom sklearn.model_selection import train_test_split",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "- 분류 Classification은 대표적인 지도학습Classification Learning 방법론이다",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    },
    "cell_id": "00003-bb96038f-ea98-4c2d-a6c6-e162c35bfa82",
    "deepnote_cell_type": "code"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00004-b09ac653-f27e-43f0-8d3a-d5c2e14f92ee",
    "deepnote_cell_type": "code"
   },
   "source": "#붓꽃 데이터셋을 로딩하기\niris= load_iris()\niris_data= iris.data\n#iris의 값만 가져옴\niris_data\n#iris의 label: 정답값\niris_label= iris.target\nprint('iris target값',iris_label)\nprint('iris target명',iris.target_names)\n\n#데이터프레임으로 변환하기\niris_df= pd.DataFrame(data=iris_data,columns=iris.feature_names)\niris_df['label']=iris.target\niris_df.head(10)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "iris target값 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\niris target명 ['setosa' 'versicolor' 'virginica']\n"
    },
    {
     "data": {
      "text/plain": "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n5                5.4               3.9                1.7               0.4   \n6                4.6               3.4                1.4               0.3   \n7                5.0               3.4                1.5               0.2   \n8                4.4               2.9                1.4               0.2   \n9                4.9               3.1                1.5               0.1   \n\n   label  \n0      0  \n1      0  \n2      0  \n3      0  \n4      0  \n5      0  \n6      0  \n7      0  \n8      0  \n9      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00005-cd9d5b1a-929a-4f41-ba67-6862b095a886",
    "deepnote_cell_type": "code"
   },
   "source": "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,test_size=0.2,random_state=11)\nX_train",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [6.9, 3.2, 5.7, 2.3],\n       [7.7, 2.8, 6.7, 2. ],\n       [5. , 3.3, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [7.6, 3. , 6.6, 2.1],\n       [6.7, 3. , 5. , 1.7],\n       [5.5, 3.5, 1.3, 0.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5. , 2. , 3.5, 1. ],\n       [7.9, 3.8, 6.4, 2. ],\n       [4.6, 3.4, 1.4, 0.3],\n       [6.9, 3.1, 4.9, 1.5],\n       [6.5, 3. , 5.8, 2.2],\n       [5.1, 2.5, 3. , 1.1],\n       [6.6, 2.9, 4.6, 1.3],\n       [5. , 3.2, 1.2, 0.2],\n       [7.4, 2.8, 6.1, 1.9],\n       [5.1, 3.8, 1.6, 0.2],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.9, 3. , 4.2, 1.5],\n       [4.9, 2.5, 4.5, 1.7],\n       [6.7, 3.1, 4.7, 1.5],\n       [4.4, 3.2, 1.3, 0.2],\n       [5.4, 3.4, 1.7, 0.2],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.1, 3.7, 1.5, 0.4],\n       [5. , 3.4, 1.6, 0.4],\n       [6.1, 2.6, 5.6, 1.4],\n       [6.5, 3. , 5.5, 1.8],\n       [6.3, 2.5, 5. , 1.9],\n       [5.2, 3.4, 1.4, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [6.1, 2.8, 4.7, 1.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5.6, 3. , 4.1, 1.3],\n       [6.3, 2.7, 4.9, 1.8],\n       [7.1, 3. , 5.9, 2.1],\n       [5.5, 2.6, 4.4, 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [6.3, 3.4, 5.6, 2.4],\n       [5.8, 2.7, 5.1, 1.9],\n       [5.5, 4.2, 1.4, 0.2],\n       [5.6, 2.7, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [6.7, 2.5, 5.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.7, 3.1, 5.6, 2.4],\n       [4.6, 3.2, 1.4, 0.2],\n       [7.7, 3.8, 6.7, 2.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5.7, 3.8, 1.7, 0.3],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.5, 1.4, 0.3],\n       [6.3, 3.3, 6. , 2.5],\n       [4.4, 3. , 1.3, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5.1, 3.8, 1.5, 0.3],\n       [6. , 2.9, 4.5, 1.5],\n       [5.2, 4.1, 1.5, 0.1],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.2, 2.2, 4.5, 1.5],\n       [6.4, 3.1, 5.5, 1.8],\n       [6.3, 2.3, 4.4, 1.3],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [5.2, 2.7, 3.9, 1.4],\n       [5.7, 2.8, 4.1, 1.3],\n       [7. , 3.2, 4.7, 1.4],\n       [6.7, 3.3, 5.7, 2.5],\n       [5.5, 2.3, 4. , 1.3],\n       [5.4, 3.9, 1.7, 0.4],\n       [5.7, 3. , 4.2, 1.2],\n       [6.4, 3.2, 5.3, 2.3],\n       [5. , 3.5, 1.3, 0.3],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [5.7, 2.8, 4.5, 1.3],\n       [5. , 3.4, 1.5, 0.2],\n       [5.8, 4. , 1.2, 0.2],\n       [5.1, 3.8, 1.9, 0.4],\n       [5.6, 2.8, 4.9, 2. ],\n       [4.9, 2.4, 3.3, 1. ],\n       [5.4, 3.7, 1.5, 0.2],\n       [7.3, 2.9, 6.3, 1.8],\n       [5.5, 2.5, 4. , 1.3],\n       [7.7, 3. , 6.1, 2.3],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [5.7, 2.9, 4.2, 1.3],\n       [5.7, 2.6, 3.5, 1. ],\n       [6. , 3. , 4.8, 1.8],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.4, 2.8, 5.6, 2.1],\n       [5.8, 2.8, 5.1, 2.4],\n       [5.9, 3.2, 4.8, 1.8],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [6.5, 3. , 5.2, 2. ],\n       [4.9, 3.6, 1.4, 0.1],\n       [6.4, 2.9, 4.3, 1.3],\n       [7.2, 3. , 5.8, 1.6],\n       [4.9, 3.1, 1.5, 0.2],\n       [6.4, 2.8, 5.6, 2.2],\n       [7.2, 3.2, 6. , 1.8],\n       [4.8, 3. , 1.4, 0.3],\n       [5.8, 2.6, 4. , 1.2],\n       [7.2, 3.6, 6.1, 2.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5.8, 2.7, 3.9, 1.2],\n       [6.1, 2.8, 4. , 1.3],\n       [6.8, 2.8, 4.8, 1.4],\n       [4.3, 3. , 1.1, 0.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [6.1, 3. , 4.6, 1.4],\n       [5.5, 2.4, 3.8, 1.1]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00006-c4a74bba-b90b-4571-a05a-47eb90ba49d6",
    "deepnote_cell_type": "code"
   },
   "source": "#모델 생성하기\nDTC= DecisionTreeClassifier(random_state=11)\n#모델 학습시키기\nDTC.fit(X_train,y_train)\n#학습이 완료된 모델 객체와 테스트 데이터셋을 활용하여 예측하기\npred= DTC.predict(X_test)\n#정확도 측정하기\nprint(f'예측 정확도: {accuracy_score(y_test,pred):.3f}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "예측 정확도: 0.933\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00007-c1bf8610-e754-4d20-8534-977e6aa5de3b",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.datasets import load_iris\n\niris_data= load_iris()\nprint(type(iris_data))\n\nkeys= iris_data.keys()\nprint('붓꽃 데이터 세트의 키들',keys)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'sklearn.utils.Bunch'>\n붓꽃 데이터 세트의 키들 dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00008-c53cd0b0-db8f-4f79-bedd-2239f86219fc",
    "deepnote_cell_type": "code"
   },
   "source": "print('\\n feature_names 의 type',type(iris_data.feature_names))\nprint('feature_names의 shape', len(iris_data.feature_names))\nprint(iris_data.feature_names)\n\nprint('\\n target_names의 type',type(iris_data.target_names))\nprint('target_names의 shape:',len(iris_data.target_names))\nprint(iris_data.target_names)\n\nprint('\\n data의 type:', type(iris_data.data))\nprint('data의 shape',iris_data.data.shape)\nprint(iris_data['data'])\n\nprint('\\n target의 type:',type(iris_data.target))\nprint('target의 shape:',iris_data.target.shape)\nprint(iris_data.target)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n feature_names 의 type <class 'list'>\nfeature_names의 shape 4\n['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n\n target_names의 type <class 'numpy.ndarray'>\ntarget_names의 shape: 3\n['setosa' 'versicolor' 'virginica']\n\n data의 type: <class 'numpy.ndarray'>\ndata의 shape (150, 4)\n[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\n\n target의 type: <class 'numpy.ndarray'>\ntarget의 shape: (150,)\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00009-c55a5bea-3994-452a-a88b-eeaa4993cb57",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n\nDTC= DecisionTreeClassifier()\niris_data=load_iris()\n#훈련/테스트용 데이터 분리하기\nX_train,X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,test_size=0.3,random_state=121)\n#모델 학습시키기\nDTC.fit(X_train,y_train)\npred= DTC.predict(X_test)\nprint(f'예측 정확도는 {accuracy_score(y_test,pred):.4f} 입니다')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "예측 정확도는 0.9556 입니다\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00010-c435b356-2f4e-4c32-9f26-15c77274b263",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\niris = load_iris()\nfeatures= iris.data\nlabel= iris.target\nDTC= DecisionTreeClassifier(random_state=156)\n\n#5개의 폴드 세트로 분리하는 K-Fold객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\nkfold= KFold(n_splits=5)\ncv_accuracy=[]\nprint('붓꽃 데이터 크기:',features.shape[0])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "붓꽃 데이터 크기: 150\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00011-bcf8ef54-719b-41d2-a0b6-996271e95bb0",
    "deepnote_cell_type": "code"
   },
   "source": "#전체 데이터는 150 => 학습은 150*4/5=120, 검증은 30\nn_iter=0\n# KFold 객체의 split()을 호출하면 폴드용 학습용, 검증용 테스트의 로우 인덱스를 array로 반환한다\nfor train_index, test_index in kfold.split(features):\n    #kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test= label[train_index], label[test_index]\n    #학습 및 예측\n    DTC.fit(X_train,y_train)\n    pred=DTC.predict(X_test)\n    n_iter= n_iter+1\n    #반복시마다 정확도를 측정한다\n    accuracy= np.round(accuracy_score(y_test,pred),4)\n    train_size= X_train.shape[0]\n    test_size= X_test.shape[0]\n    print(f'{n_iter} 교차 검증 정확도: {accuracy} 학습 데이터 크기: {train_size} 검증 데이터 크기{test_size}')\n    print(f'{n_iter} 검증 세트 인덱스{test_index}')\n    cv_accuracy.append(accuracy)\n\n#반복할 때마다 계산된 정확도를 평균한다\nprint(f'평균 검증 정확도{np.mean(cv_accuracy)}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1 교차 검증 정확도: 1.0 학습 데이터 크기: 120 검증 데이터 크기30\n1 검증 세트 인덱스[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29]\n2 교차 검증 정확도: 0.9667 학습 데이터 크기: 120 검증 데이터 크기30\n2 검증 세트 인덱스[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n 54 55 56 57 58 59]\n3 교차 검증 정확도: 0.8667 학습 데이터 크기: 120 검증 데이터 크기30\n3 검증 세트 인덱스[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n 84 85 86 87 88 89]\n4 교차 검증 정확도: 0.9333 학습 데이터 크기: 120 검증 데이터 크기30\n4 검증 세트 인덱스[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119]\n5 교차 검증 정확도: 0.7333 학습 데이터 크기: 120 검증 데이터 크기30\n5 검증 세트 인덱스[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n 138 139 140 141 142 143 144 145 146 147 148 149]\n평균 검증 정확도0.9\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00012-54457a32-0cef-4266-95c6-974c9797c802",
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\n\niris= load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\niris_df['label'] = iris.target\niris_df['label'].value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": "0    50\n1    50\n2    50\nName: label, dtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00013-fb326b29-0fa7-40bb-8196-85e7ba5f7077",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.model_selection import StratifiedKFold\n\nskf= StratifiedKFold(n_splits=3)\nn_iter=0\n\n#레이블 분포도에 따라 학습/검증 데이터를 나누기 때문에 split argument에 레이블 데이터도 필요하다\nfor train_index, test_index in skf.split(iris_df, iris_df['label']):\n    n_iter = n_iter +1\n    label_train = iris_df['label'].iloc[train_index]\n    label_test = iris_df['label'].iloc[test_index]\n    print(f'교차 검증: {n_iter}')\n    print(f'학습 레이블 데이터 분포\\n', label_train.value_counts())\n    print(f'검증 레이블 데이터 분포\\n', label_test.value_counts())\n\n\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "교차 검증: 1\n학습 레이블 데이터 분포\n 2    34\n0    33\n1    33\nName: label, dtype: int64\n검증 레이블 데이터 분포\n 0    17\n1    17\n2    16\nName: label, dtype: int64\n교차 검증: 2\n학습 레이블 데이터 분포\n 1    34\n0    33\n2    33\nName: label, dtype: int64\n검증 레이블 데이터 분포\n 0    17\n2    17\n1    16\nName: label, dtype: int64\n교차 검증: 3\n학습 레이블 데이터 분포\n 0    34\n1    33\n2    33\nName: label, dtype: int64\n검증 레이블 데이터 분포\n 1    17\n2    17\n0    16\nName: label, dtype: int64\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00014-8b845df0-7bba-4d65-a1a0-8807c00f106d",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.model_selection import StratifiedKFold\n\nskf= StratifiedKFold(n_splits=3)\nn_iter=0\ncv_accuracy=[]\n\n#레이블 분포도에 따라 학습/검증 데이터를 나누기 때문에 split argument에 레이블 데이터도 필요하다\nfor train_index, test_index in skf.split(features,label):\n    #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터를 추출하기\n    X_train, X_test= features[train_index], features[test_index]\n    y_train, y_test = label[train_index], label[test_index]\n    #학습 및 예측\n    DTC.fit(X_train, y_train)\n    pred= DTC.predict(X_test)\n\n    #반복시마다 정확도 측정\n    n_iter=n_iter +1\n    accuracy= np.round(accuracy_score(y_test,pred),4)\n    train_size= X_train.shape[0]\n    test_size= X_test.shape[0]\n    print(f'\\n {n_iter} 교차 검증 정확도:{accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기:{test_size}')\n    print(f'{n_iter} 검증 세트 인덱스 {test_index}')\n    cv_accuracy.append(accuracy)\n\n#교차 검증별 정확도 및 평균 정확도 계산\nprint('\\n 교차 검증별 정확도:' ,np.round(cv_accuracy,4))\nprint('평균 검증 정확도:',np.round(np.mean(cv_accuracy),4))\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n 1 교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기:50\n1 검증 세트 인덱스 [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n\n 2 교차 검증 정확도:0.94, 학습 데이터 크기: 100, 검증 데이터 크기:50\n2 검증 세트 인덱스 [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n\n 3 교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기:50\n3 검증 세트 인덱스 [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n\n 교차 검증별 정확도: [0.98 0.94 0.98]\n평균 검증 정확도: 0.9667\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00015-ee63375d-ff7c-45d4-98c4-6b707186e7d4",
    "deepnote_cell_type": "code"
   },
   "source": "#관련 모듈 import 하기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.datasets import load_iris\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00016-f19dd666-6686-481b-8ece-60130dcab3d1",
    "deepnote_cell_type": "code"
   },
   "source": "iris_data= load_iris()\nDTC= DecisionTreeClassifier(random_state=156)\n\ndata= iris_data.data\nlabel= iris_data.target\n\n#성능 지표는 정확도(accuracy), 교차 검증 세트는 3개로 정한다\nscores=cross_val_score(DTC,data,label,scoring='accuracy',cv=3)\nprint('교차 검증별 정확도:',np.round(scores,4))\nprint('평균 검증 정확도',np.round(np.mean(scores),4))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "교차 검증별 정확도: [0.98 0.94 0.98]\n평균 검증 정확도 0.9667\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00017-f147f918-6cfe-431a-8c12-b8d203ad0642",
    "deepnote_cell_type": "code"
   },
   "source": "grid_parameter= {'max_depth':[1,2,3],\n                 'min_samples_split':[2,3]}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00018-c15ebe6d-edd9-4d2a-a5b1-a99cf398c2ad",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#데이터를 로딩하고 학습 데이터와 테스트 데이터를 분리시킨다\niris_data= load_iris()\nX_train, X_test, y_train, y_test = train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=121)\n\ndtree=DecisionTreeClassifier()\n\n#하이퍼 파라미터를 딕셔너리 형태로 만든다\nparameters= {'max_depth':[1,2,3],'min_samples_split':[2,3]}\n\n#parameter_grid의 하이퍼 파라미터를 3개의 train<test set fold로 나누어 테스트를 수행한다\ngrid_dtree= GridSearchCV(dtree,param_grid=parameters, cv=3 ,refit=True)\n\n#붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습 및 평가\ngrid_dtree.fit(X_train,y_train)\n\n#GridsearchCV 결과를 추출하여 DataFrame으로 변환시킨다\nscores_df= pd.DataFrame(grid_dtree.cv_results_)\nscores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00019-c719c824-1cd0-4ef3-80b1-0470532a15b1",
    "deepnote_cell_type": "code"
   },
   "source": "#parameter_grid의 하이퍼 파라미터를 3개의 train<test set fold로 나누어 테스트를 수행한다\ngrid_dtree= GridSearchCV(dtree,param_grid=parameters, cv=3 ,refit=True)\n\n#붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습 및 평가\ngrid_dtree.fit(X_train,y_train)\n\n#GridsearchCV 결과를 추출하여 DataFrame으로 변환시킨다\nscores_df= pd.DataFrame(grid_dtree.cv_results_)\nscores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]",
   "outputs": [
    {
     "data": {
      "text/plain": "                                     params  mean_test_score  rank_test_score  \\\n0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n\n   split0_test_score  split1_test_score  split2_test_score  \n0              0.700                0.7               0.70  \n1              0.700                0.7               0.70  \n2              0.925                1.0               0.95  \n3              0.925                1.0               0.95  \n4              0.975                1.0               0.95  \n5              0.975                1.0               0.95  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00020-a7a267c1-be6c-4cb6-b6ba-c944f8c5ef6f",
    "deepnote_cell_type": "code"
   },
   "source": "print('GridSearchCV 최적 파라미터는 ',grid_dtree.best_params_)\nprint(f'GridSearchCV 최고 정확도는 {grid_dtree.best_score_:.3f}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "GridSearchCV 최적 파라미터는  {'max_depth': 3, 'min_samples_split': 2}\nGridSearchCV 최고 정확도는 0.975\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00021-99115d55-dbcc-4da9-ba07-dd86bfebb344",
    "deepnote_cell_type": "code"
   },
   "source": "#GridSearchCV의 reft으로 이미 학습된 estimator 반환시키기\nestimator = grid_dtree.best_estimator_\n\n#GridSearchCV의 best_estimator_는 이미 최적 학습이 되었으므로 별도의 학습이 필요없다\npred= estimator.predict(X_test)\nprint(f'테스트 데이터 셋의 정확도는 {accuracy_score(y_test,pred):.4f} 입니다')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "테스트 데이터 셋의 정확도는 0.9667 입니다\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00022-677f0bf5-66b6-42a9-983c-92d17fde8546",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import LabelEncoder\nitems=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n\n#LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩을 수행한다\nencoder= LabelEncoder()\nencoder.fit(items)\nlabels= encoder.transform(items)\nprint('인코딩 변환값',labels)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "인코딩 변환값 [0 1 4 5 3 3 2 2]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00023-a90f7479-42e5-468a-8a54-f190a6bfd26a",
    "deepnote_cell_type": "code"
   },
   "source": "print('인코딩 클래스',encoder.classes_)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "인코딩 클래스 ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00024-46d2c902-2df7-4193-b07e-5abec2090ee1",
    "deepnote_cell_type": "code"
   },
   "source": "print('디코딩 원본값:',encoder.inverse_transform([4,5,2,0,1,1,3,3]))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00025-f0e28fed-cd08-46e6-b581-65719925c085",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\nitems=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n#2차원 넘파이 배열로 변환한다\nitems= np.array(items).reshape(-1,1)\n\n#원- 핫 인코딩을 적용한다\noh_encoder= OneHotEncoder()\noh_encoder.fit(items)\noh_labels= oh_encoder.transform(items)\n\n#OneHotEncdoer로 변환한 결과는 희소행렬이므로 toarray()를 통해 밀집 행렬로 변환할 수 있다\nprint('원-핫 인코딩 데이터')\nprint(oh_labels.toarray())\nprint('원-핫 인코딩 데이터 차원')\nprint(oh_labels.shape)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "원-핫 인코딩 데이터\n[[1. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]]\n원-핫 인코딩 데이터 차원\n(8, 6)\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00026-fcc20645-9b3c-43d1-8692-45d69eef37d9",
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\ndf= pd.DataFrame({'items':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']})\npd.get_dummies(df)",
   "outputs": [
    {
     "data": {
      "text/plain": "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n0         1          0         0          0            0          0\n1         0          1         0          0            0          0\n2         0          0         0          0            1          0\n3         0          0         0          0            0          1\n4         0          0         0          1            0          0\n5         0          0         0          1            0          0\n6         0          0         1          0            0          0\n7         0          0         1          0            0          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>items_TV</th>\n      <th>items_냉장고</th>\n      <th>items_믹서</th>\n      <th>items_선풍기</th>\n      <th>items_전자레인지</th>\n      <th>items_컴퓨터</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00027-b3b39d97-fb40-4b10-b619-677f1ca406a7",
    "deepnote_cell_type": "code"
   },
   "source": "#StandardScaler\nfrom sklearn.datasets import load_iris\nimport pandas as pd\n#붓꽃 데이터를 로딩하고 Dataframe으로 변환한다\niris= load_iris()\niris_data= iris.data\niris_df = pd.DataFrame(data=iris_data,columns=iris.feature_names)\n\nprint(f'feature들의 평균값은 \\n{iris_df.mean()}')\nprint(f'\\nfeature들의 분산값은 \\n{iris_df.var()}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "feature들의 평균값은 \nsepal length (cm)    5.843333\nsepal width (cm)     3.057333\npetal length (cm)    3.758000\npetal width (cm)     1.199333\ndtype: float64\n\nfeature들의 분산값은 \nsepal length (cm)    0.685694\nsepal width (cm)     0.189979\npetal length (cm)    3.116278\npetal width (cm)     0.581006\ndtype: float64\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00028-6540989c-ce31-4752-be34-383a34663e7f",
    "deepnote_cell_type": "code"
   },
   "source": "#이제 StandardScaler를 활용하여 정규화하기\nfrom sklearn.preprocessing import StandardScaler\n\n#StandardScaler 객체 생성하기\nscaler= StandardScaler()\n#StandardScaler로 데이터 세트 변환. fit() 과 trnasformation() 호출\nscaler.fit(iris_df)\niris_scaled=scaler.transform(iris_df)\n\n#transform()시 스케일 변환된 데이터 셋이 넘파이 배열로 변환되어 이를 데이터프레임으로 변환한다\niris_df_scaled= pd.DataFrame(data=iris_scaled,columns=iris.feature_names)\nprint(f'features의 평군값은 \\n{iris_df_scaled.mean()}\\n이다')\nprint(f'feature들의 분산 값은 \\n{iris_df_scaled.var()}\\n이다')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "features의 평군값은 \nsepal length (cm)   -1.690315e-15\nsepal width (cm)    -1.842970e-15\npetal length (cm)   -1.698641e-15\npetal width (cm)    -1.409243e-15\ndtype: float64\n이다\nfeature들의 분산 값은 \nsepal length (cm)    1.006711\nsepal width (cm)     1.006711\npetal length (cm)    1.006711\npetal width (cm)     1.006711\ndtype: float64\n이다\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00029-5935f5e3-1b5b-42fe-9523-cac9160b9a8e",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import MinMaxScaler\n\n#MinMaxScaler객체 생성하기\nscaler= MinMaxScaler()\n#MinMaxSclaer로 데이터 세트 변환. fit()과 transformation() 호출하기\nscaler.fit(iris_df)\niris_scaled= scaler.transform(iris_df)\n\n#transform()시 스케일 변환된 데이터 셋이 넘파이 배열로 반환되어 이를 데이터프레임으로 변환시킨다\niris_df_scaled= pd.DataFrame(data=iris_scaled,columns=iris.feature_names)\nprint(f'feature들의 최솟값은 \\n{iris_df_scaled.min()}\\n입니다')\nprint(f'feature들의 최댓값은 \\n{iris_df_scaled.max()}\\n입니다')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "feature들의 최솟값은 \nsepal length (cm)    0.0\nsepal width (cm)     0.0\npetal length (cm)    0.0\npetal width (cm)     0.0\ndtype: float64\n입니다\nfeature들의 최댓값은 \nsepal length (cm)    1.0\nsepal width (cm)     1.0\npetal length (cm)    1.0\npetal width (cm)     1.0\ndtype: float64\n입니다\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00030-d9d5ab64-1ca7-4660-8ed9-f9ecf25f2b0f",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\n#학습 데이터는 0~10까지, 테스트 데이터는 0~5까지 값을 갖는 데이터 셋으로 생성\n#Scaler 클래스의 fit(),transform()은 2차원 이상 데이터만 사용가능 하므로 reshape(-1,1)으로 차원 변경을 한다\ntrain_arr=np.arange(0,11).reshape(-1,1)\ntest_arr=np.arange(0,6).reshape(-1,1)\n\n#MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환한다\nscaler= MinMaxScaler()\n#fit()하게 되면 train_arr 데이터 최솟값이 0, 최댓값이 10으로 설정된다\nscaler.fit(train_arr)\n# train_arr에 1/10을 곱한값으로 train_scaled 데이터가 변환됨.\ntrain_scaled= scaler.transform(train_arr)\n\nprint(f'원본 train_arr 데이터는 {np.round(train_arr.reshape(-1),2)}')\nprint(f'scaled train_arr 데이터는 {np.round(train_scaled.reshape(-1),2)}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "원본 train_arr 데이터는 [ 0  1  2  3  4  5  6  7  8  9 10]\nscaled train_arr 데이터는 [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00031-07d8e525-09ee-4da2-b32b-32e328cdc4c7",
    "deepnote_cell_type": "code"
   },
   "source": "#MinMaxScaler에 test_arr를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\nscaler.fit(test_arr)\n#test_arr에 1/5를 곱한값으로 test_scaled가 반환됨\ntest_scaled= scaler.transform(test_arr)\n\n#test_arr의 scale 변환 출력\nprint(f'원본 test_arr 데이터:{np.round(test_arr.reshape(-1),2)}')\nprint(f'scaled test_arr 데이터:{np.round(test_scaled.reshape(-1),2)}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "원본 test_arr 데이터:[0 1 2 3 4 5]\nscaled test_arr 데이터:[0.  0.2 0.4 0.6 0.8 1. ]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 사이킷런으로 수행하는 타이타닉 생존 예측",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "cell_id": "00032-b4744fa7-66b8-42cc-b101-4f820b0ef1ed",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "- passengerid: 탑승자 데이터 일련번호\n- survived: 생존 여부 0: 사망, 1: 생존\n- pclass: 티켓의 선실 등급 1:1등석, 2:2등석 3:3등석\n- sex: 탑승자 성별\n- name: 탑승자 이름\n- age: 탑승자 나이\n- sibsp: 같이 탑승한 형제자매 또는 배우자의 인원수\n- parch:같이 탑승한 부모님 또는 어린이 인원 수\n- ticket: 티켓 번호\n- fare: 요금\n- cabin: 선실번호\n- embarked:중간 정착 항구",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "cell_id": "00033-0e0d0e19-c4b5-4adc-8e7c-640d1a287130",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00034-9b21cbc3-4a52-432d-a846-0144a247cd98",
    "deepnote_cell_type": "code"
   },
   "source": "df_titanic= pd.read_csv('./train.csv')\ndf_titanic.head(10)",
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00035-13279448-fcc3-4304-83e4-2c00afe2be08",
    "deepnote_cell_type": "code"
   },
   "source": "#데이터 정보 확인하기\nprint(df_titanic.shape) # 891 * 12: 데이터 891개, 컬럼 12개\ndf_titanic.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(891, 12)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00036-a2211dbe-54b3-4d4f-916b-8aff4bb527d6",
    "deepnote_cell_type": "code"
   },
   "source": "#결측치 확인하기 => Age 177, Cabin 687개 Embarked 2개이다\ndf_titanic.isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00037-b1396af0-d2f8-451c-aa7f-1d75278e9689",
    "deepnote_cell_type": "code"
   },
   "source": "#기술 통계량 확인하기\ndf_stats= df_titanic.describe().T\ndf_stats",
   "outputs": [
    {
     "data": {
      "text/plain": "             count        mean         std   min       25%       50%    75%  \\\nPassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \nSurvived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \nPclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \nAge          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \nSibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \nParch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \nFare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n\n                  max  \nPassengerId  891.0000  \nSurvived       1.0000  \nPclass         3.0000  \nAge           80.0000  \nSibSp          8.0000  \nParch          6.0000  \nFare         512.3292  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>PassengerId</th>\n      <td>891.0</td>\n      <td>446.000000</td>\n      <td>257.353842</td>\n      <td>1.00</td>\n      <td>223.5000</td>\n      <td>446.0000</td>\n      <td>668.5</td>\n      <td>891.0000</td>\n    </tr>\n    <tr>\n      <th>Survived</th>\n      <td>891.0</td>\n      <td>0.383838</td>\n      <td>0.486592</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>891.0</td>\n      <td>2.308642</td>\n      <td>0.836071</td>\n      <td>1.00</td>\n      <td>2.0000</td>\n      <td>3.0000</td>\n      <td>3.0</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>714.0</td>\n      <td>29.699118</td>\n      <td>14.526497</td>\n      <td>0.42</td>\n      <td>20.1250</td>\n      <td>28.0000</td>\n      <td>38.0</td>\n      <td>80.0000</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>891.0</td>\n      <td>0.523008</td>\n      <td>1.102743</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0</td>\n      <td>8.0000</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>891.0</td>\n      <td>0.381594</td>\n      <td>0.806057</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>6.0000</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>891.0</td>\n      <td>32.204208</td>\n      <td>49.693429</td>\n      <td>0.00</td>\n      <td>7.9104</td>\n      <td>14.4542</td>\n      <td>31.0</td>\n      <td>512.3292</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 데이터 전처리 계획\n- 결측치 처리하기\n- 문자열-카테고리 변수 인코딩 하기\n- 피쳐 스케일링 하기\n- 불필요해보이는 피처 제거하기\n## 학습 계획\n- 훈련, 테스트 데이터 분리(이미 분리된 데이터를 제공받음)\n- 모델 세우기\n- 학습 및 평가\n# 분석 계획\n- 그래프 시각화\n- 증거를 기반으로 한 추론 제시",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "cell_id": "00038-813d6380-b011-44ef-b11f-6aa70d1398e7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00039-e62a3188-1945-46d2-8e39-127fbd574c84",
    "deepnote_cell_type": "code"
   },
   "source": "# 결측치 처리하기\n# 이 책에선 age는 열의 평균으로, 나머지 변수들은 'N'값으로 체우기로 결정한다\ndf_titanic['Age'].fillna(df_titanic['Age'].mean(),inplace=True)\ndf_titanic['Cabin'].fillna('N',inplace=True)\ndf_titanic['Embarked'].fillna('N',inplace=True)\nprint(f'데이터 셋 Null값 개수는 {df_titanic.isnull().sum().sum()}개 입니다')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "데이터 셋 Null값 개수는 0개 입니다\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00040-08a4ade5-cf9d-457d-9d1c-5ce184b4b65b",
    "deepnote_cell_type": "code"
   },
   "source": "#문자열- 카테고리 피처 Sex,Cabin,Embarked를 인코딩하기\nfrom sklearn.preprocessing import LabelEncoder\n\n#한번만 인코딩해야됨. 두번하면 안됨\ncategories_backup=[]\nfeatures=['Cabin','Sex','Embarked']\nfor feature in features:\n    LE= LabelEncoder()\n    LE= LE.fit(df_titanic[feature])\n    #카테고리 백업해두기\n    categories_backup.append(list(LE.classes_))\n    #인코딩하기\n    df_titanic[feature]= LE.transform(df_titanic[feature])\n\ndf_titanic.head(10)\nprint(categories_backup)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[['A10', 'A14', 'A16', 'A19', 'A20', 'A23', 'A24', 'A26', 'A31', 'A32', 'A34', 'A36', 'A5', 'A6', 'A7', 'B101', 'B102', 'B18', 'B19', 'B20', 'B22', 'B28', 'B3', 'B30', 'B35', 'B37', 'B38', 'B39', 'B4', 'B41', 'B42', 'B49', 'B5', 'B50', 'B51 B53 B55', 'B57 B59 B63 B66', 'B58 B60', 'B69', 'B71', 'B73', 'B77', 'B78', 'B79', 'B80', 'B82 B84', 'B86', 'B94', 'B96 B98', 'C101', 'C103', 'C104', 'C106', 'C110', 'C111', 'C118', 'C123', 'C124', 'C125', 'C126', 'C128', 'C148', 'C2', 'C22 C26', 'C23 C25 C27', 'C30', 'C32', 'C45', 'C46', 'C47', 'C49', 'C50', 'C52', 'C54', 'C62 C64', 'C65', 'C68', 'C7', 'C70', 'C78', 'C82', 'C83', 'C85', 'C86', 'C87', 'C90', 'C91', 'C92', 'C93', 'C95', 'C99', 'D', 'D10 D12', 'D11', 'D15', 'D17', 'D19', 'D20', 'D21', 'D26', 'D28', 'D30', 'D33', 'D35', 'D36', 'D37', 'D45', 'D46', 'D47', 'D48', 'D49', 'D50', 'D56', 'D6', 'D7', 'D9', 'E10', 'E101', 'E12', 'E121', 'E17', 'E24', 'E25', 'E31', 'E33', 'E34', 'E36', 'E38', 'E40', 'E44', 'E46', 'E49', 'E50', 'E58', 'E63', 'E67', 'E68', 'E77', 'E8', 'F E69', 'F G63', 'F G73', 'F2', 'F33', 'F38', 'F4', 'G6', 'N', 'T'], ['female', 'male'], ['C', 'N', 'Q', 'S']]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00041-0799432b-1e24-4b7e-86ac-88a88676899f",
    "deepnote_cell_type": "code"
   },
   "source": "#인코딩한 데이터 백업해보기\nLE= LabelEncoder()\nLE=LE.fit(categories_backup[1])\nLE.inverse_transform(df_titanic['Sex'])",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['male', 'female', 'female', 'female', 'male', 'male', 'male',\n       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n       'female', 'female', 'male', 'male', 'female', 'female', 'male',\n       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n       'male', 'male', 'male', 'female', 'female', 'female', 'female',\n       'male', 'female', 'female', 'male', 'male', 'female', 'male',\n       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n       'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male',\n       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n       'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female',\n       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n       'female', 'male', 'male', 'male', 'female', 'male', 'female',\n       'male', 'female', 'female', 'male', 'male', 'female', 'female',\n       'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n       'female', 'female', 'male', 'female', 'male', 'male', 'male',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n       'male', 'male', 'female', 'female', 'male', 'male', 'male',\n       'female', 'male', 'male', 'female', 'female', 'female', 'female',\n       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n       'male', 'male', 'male', 'female', 'female', 'male', 'male',\n       'female', 'male', 'female', 'female', 'female', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n       'female', 'female', 'male', 'female', 'female', 'male', 'male',\n       'female', 'female', 'male', 'female', 'male', 'female', 'female',\n       'female', 'female', 'male', 'male', 'male', 'female', 'male',\n       'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male',\n       'male', 'female', 'female', 'female', 'male', 'male', 'male',\n       'male', 'male', 'male', 'male', 'male', 'female', 'female',\n       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n       'male', 'male', 'female', 'female', 'female', 'male', 'male',\n       'male', 'female', 'female', 'male', 'female', 'male', 'male',\n       'male', 'female', 'male', 'female', 'male', 'male', 'male',\n       'female', 'female', 'male', 'female', 'male', 'male', 'female',\n       'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male',\n       'male', 'female', 'male', 'male', 'female', 'male', 'male',\n       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n       'male', 'female', 'male', 'male', 'female', 'female', 'male',\n       'male', 'male', 'female', 'female', 'male', 'male', 'female',\n       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n       'male', 'female', 'female', 'female', 'male', 'female', 'male',\n       'female', 'female', 'female', 'female', 'male', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'female', 'male', 'female', 'female', 'male',\n       'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male',\n       'male', 'male', 'female', 'male', 'female', 'male', 'male',\n       'female', 'female', 'female', 'male', 'female', 'female', 'male',\n       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n       'male', 'male', 'female', 'male', 'female', 'female', 'male',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n       'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female',\n       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n       'female', 'male', 'female', 'female', 'male', 'male', 'female',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n       'male', 'male', 'male', 'female', 'female', 'male', 'female',\n       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n       'male', 'male', 'female', 'male', 'female', 'male', 'female',\n       'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male',\n       'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female',\n       'female', 'male', 'female', 'female', 'male', 'male', 'male',\n       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n       'male', 'male', 'female', 'female', 'male', 'female', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n       'female', 'male', 'male', 'male', 'male', 'male', 'female',\n       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n       'female', 'female', 'female', 'female', 'male', 'female', 'male',\n       'male', 'male', 'female', 'female', 'male', 'female', 'female',\n       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n       'female', 'male', 'male', 'male', 'female', 'female', 'male',\n       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n       'male', 'male'], dtype='<U6')"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00042-1557267f-0728-4db3-8bec-4e91af43f998",
    "deepnote_cell_type": "code"
   },
   "source": "#불필요해보이는 피처 제거하기\ndf_titanic.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00043-bee7b52f-2e98-4593-9f5a-5e2af41279da",
    "deepnote_cell_type": "code"
   },
   "source": "df_titanic",
   "outputs": [
    {
     "data": {
      "text/plain": "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n0           0       3    male  22.0      1      0   7.2500   NaN        S\n1           1       1  female  38.0      1      0  71.2833   C85        C\n2           1       3  female  26.0      0      0   7.9250   NaN        S\n3           1       1  female  35.0      1      0  53.1000  C123        S\n4           0       3    male  35.0      0      0   8.0500   NaN        S\n..        ...     ...     ...   ...    ...    ...      ...   ...      ...\n886         0       2    male  27.0      0      0  13.0000   NaN        S\n887         1       1  female  19.0      0      0  30.0000   B42        S\n888         0       3  female   NaN      1      2  23.4500   NaN        S\n889         1       1    male  26.0      0      0  30.0000  C148        C\n890         0       3    male  32.0      0      0   7.7500   NaN        Q\n\n[891 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00044-c5b7336d-2f56-48cf-8e13-20d16a388c85",
    "deepnote_cell_type": "code"
   },
   "source": "#데이터 전처리: Null값 처리/ 불필요 피처 제거/ 문자열-카테고리 인코딩을 일괄적으로 수행할 수 있겠끔 함수로 만들기\n\n# 결측치 처리하기\ndef fillna(df):\n    # 이 책에선 age는 열의 평균으로, 나머지 변수들은 'N'값으로 체우기로 결정한다\n    df['Age'].fillna(df['Age'].mean(),inplace=True)\n    df['Cabin'].fillna('N',inplace=True)\n    df['Embarked'].fillna('N',inplace=True)\n    return df\n\n#불필요해보이는 피처 제거하기\ndef drop_features(df):\n    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n    return df\n\n#문자열- 카테고리 피처 Sex,Cabin,Embarked를 인코딩하기\ndef encoding_features(df):\n    #한번만 인코딩해야됨. 두번하면 안됨\n    categories_backup=[]\n    features=['Cabin','Sex','Embarked']\n    for feature in features:\n        LE= LabelEncoder()\n        LE= LE.fit(df[feature])\n        #카테고리 백업해두기\n        categories_backup.append(list(LE.classes_))\n        #인코딩하기\n        df[feature]= LE.transform(df[feature])\n    return df\n\n#앞에서 정의한 전처리 함수들을 호출하여 한번에 전처리를 완료하기\ndef preprocessing_feature(df):\n    df= fillna(df)\n    df= drop_features(df)\n    df= encoding_features(df)\n    return df\n\n\ndf_titanic= pd.read_csv('./train.csv')\ny_titanic_df= df_titanic['Survived']\nX_titanic_df= df_titanic.drop('Survived',axis=1)\nX_titanic_df= preprocessing_feature(X_titanic_df)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00045-1b01c191-2b01-4e92-838c-0adf99a1cb3e",
    "deepnote_cell_type": "code"
   },
   "source": "y_titanic_df",
   "outputs": [
    {
     "data": {
      "text/plain": "0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n886    0\n887    1\n888    0\n889    1\n890    0\nName: Survived, Length: 891, dtype: int64"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00046-b31afa8e-73ac-42d5-b231-d53e708faf8d",
    "deepnote_cell_type": "code"
   },
   "source": "X_titanic_df.groupby('Cabin').count()",
   "outputs": [
    {
     "data": {
      "text/plain": "       Pclass  Sex  Age  SibSp  Parch  Fare  Embarked\nCabin                                                \n0           1    1    1      1      1     1         1\n1           1    1    1      1      1     1         1\n2           1    1    1      1      1     1         1\n3           1    1    1      1      1     1         1\n4           1    1    1      1      1     1         1\n...       ...  ...  ...    ...    ...   ...       ...\n143         1    1    1      1      1     1         1\n144         2    2    2      2      2     2         2\n145         4    4    4      4      4     4         4\n146       687  687  687    687    687   687       687\n147         1    1    1      1      1     1         1\n\n[148 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>Cabin</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>687</td>\n      <td>687</td>\n      <td>687</td>\n      <td>687</td>\n      <td>687</td>\n      <td>687</td>\n      <td>687</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>148 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00047-8c16b993-b892-484d-bee2-3d26e34bfa5b",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n#결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\nDTC= DecisionTreeClassifier(random_state=11)\nRFC= RandomForestClassifier(random_state=11)\nLR= LogisticRegression(solver='liblinear')\n\n#DecisionTreeClassifier 학습/예측/평가\nDTC.fit(X_train,y_train)\nDT_pred=DTC.predict(X_test)\nprint(f'DecisionTreeClassifier 정확도는 {accuracy_score(y_test,DT_pred):.4f}')\n\n#RandomForestClassifier 학습/예측/평가\nRFC.fit(X_train,y_train)\nRF_pred= RFC.predict(X_test)\nprint(f'RandomForestClassifier 정확도는 {accuracy_score(y_test,RF_pred):.4f}')\n\n#LogisticRegression 학습/예측/평가\nLR.fit(X_train,y_train)\nLR_pred= LR.predict(X_test)\nprint(f'LogisticRegression 정확도는 {accuracy_score(y_test,LR_pred):.4f}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DecisionTreeClassifier 정확도는 0.9667\nRandomForestClassifier 정확도는 0.9667\nLogisticRegression 정확도는 0.9000\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00048-2041c14e-a55b-488c-b17b-c4e7254573c9",
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.model_selection import KFold\n\ndef cal_fold(clf,folds=5):\n    kfold=KFold(n_splits=folds)\n    scores=[]\n\n    #KFold 교차 검증 수행\n    for iter_count, (train_index,test_index) in enumerate(kfold.split(X_titanic_df)):\n        # X_titanic_df 데이터에서 교차 검증별로 학습 과 검증 데이터를 가리키는 index를 생성한다\n        X_train,X_test= X_titanic_df.values[train_index],X_titanic_df.values[test_index]\n        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n        #classifier 학습,예측,정확도 계산\n        clf.fit(X_train,y_train)\n        predictions= clf.predict(X_test)\n        accuracy= accuracy_score(y_test,predictions)\n        scores.append(accuracy)\n        print(f'교차 검증 {iter_count:.4f} 정확도 {accuracy:.4f} ')\n\n    #5개 fold에서의 평균 정확도 계산\n    mean_score= np.mean(scores)\n    print(f'평균 정확도는 {mean_score:.4f}')\n#cal_fold 함수 호출\ncal_fold(DTC,folds=5)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "교차 검증 0.0000 정확도 0.7486 \n교차 검증 1.0000 정확도 0.7640 \n교차 검증 2.0000 정확도 0.8202 \n교차 검증 3.0000 정확도 0.7809 \n교차 검증 4.0000 정확도 0.7921 \n평균 정확도는 0.7812\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00049-c99ab9d3-f775-4c24-9f20-723d4884ee68",
    "deepnote_cell_type": "code"
   },
   "source": "#이 교차검증 함수는 StratifiedKFold를 통해 폴드 세트를 분할한다\nfrom sklearn.model_selection import cross_val_score\n\nscores= cross_val_score(DTC,X_titanic_df,y_titanic_df,cv=5)\nfor iter_count, accuracy in enumerate(scores):\n    print(f'교차 검증 {iter_count:.4f} 정확도: {accuracy:.4f}')\n\nprint(f'평균 정확도: {np.mean(scores):.4f}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "교차 검증 0.0000 정확도: 0.7486\n교차 검증 1.0000 정확도: 0.7753\n교차 검증 2.0000 정확도: 0.8090\n교차 검증 3.0000 정확도: 0.7584\n교차 검증 4.0000 정확도: 0.8034\n평균 정확도: 0.7789\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00050-6f30a092-676d-49ad-a4cb-2a09f9067709",
    "deepnote_cell_type": "code"
   },
   "source": "#GridSearchCV를 통해 DecisionTreeClassifier의 최적 하이퍼 파라미터 성능을 측적하기\nfrom sklearn.model_selection import GridSearchCV\n\nparameters={'max_depth':[2,3,5,10],\n            'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n\ngrid_dclf= GridSearchCV(DTC, param_grid=parameters, scoring='accuracy',cv=5)\ngrid_dclf.fit(X_train,y_train)\n\nprint(f'GridSearchCV 최적 하이퍼 파라미터: {grid_dclf.best_params_}')\nprint(f'GridSearchCV 최고의 정확도:{grid_dclf.best_score_}')\nbest_dlcf= grid_dclf.best_estimator_\n\n#GridSearchCV의 최적 하이퍼파라미터로 학습된 Estimator로 예측 및 평가 수행\ndpredictions= best_dlcf.predict(X_test)\naccuracy=accuracy_score(y_test,dpredictions)\nprint(f'테스트 세트에서의 DecisionTreeClassifier 정확도는 {accuracy:.4f}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\nGridSearchCV 최고의 정확도:0.975\n테스트 세트에서의 DecisionTreeClassifier 정확도는 0.9667\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00051-55b0cb43-0b15-4a2a-bc96-3e119e0f5208",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=59f71f48-e620-40de-82b6-60c121211e54' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "deepnote_notebook_id": "da1ad95d-7d78-457b-890d-04a30ed69a8d",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}